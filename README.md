# _![](images/logo.png)_: Across Tasks and Domains Transfer

<p align="center">
  <img src="images/teaser.png" width=750>
</p> 
                            
This repository contains the source code of AT/DT, proposed in the paper "Learning Across Tasks and Domains", ICCV 2019.
If you use this code in your projects, please cite our paper:

```
@inproceedings{ramirez2019,
  title     = {Learning Across and Domains},
  author    = {Zama Ramirez, Pierluigi and
                Tonioni, Alessio and
                Salti, Samuele and
                Di Stefano, Luigi},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year = {2019}
}
```

## Abstract
Recent works have proven that many relevant visual tasks are closely related one to another.
Yet, this connection is seldom deployed in practice due to the lack of practical methodologies to transfer learned concepts across different training processes. In this work, we introduce a novel adaptation framework that can operate across both task and domains. Our framework learns to transfer knowledge across tasks in a fully supervised domain (e.g. synthetic data) and use this knowledge on a different domain where we have only partial supervision (e.g. real data). Our proposal is complementary to existing domain adaptation techniques and extends them to cross tasks scenarios providing additional performance gains. We prove the effectiveness of our framework across two challenging tasks (i.e. monocular depth estimation and semantic segmentation) and four different domains (Synthia, Carla, Kitti, and Cityscapes).  

For more details:
[arXiv](https://arxiv.org/abs/1904.04744)

## Requirements

## Download pretrain models

## Train 
Coming soon.

## Inference and evaluation
